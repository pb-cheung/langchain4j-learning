# web\u670D\u52A1\u7AEF\u53E3\u53F7
server.port=8080

# \u6D4B\u8BD5demo\u914D\u7F6E
#langchain4j.open-ai.chat-model.base-url=http://langchain4j.dev/demo/openai/v1
#langchain4j.open-ai.chat-model.api-key=demo
#langchain4j.open-ai.chat-model.model-name=gpt-4o-mini

langchain4j.open-ai.chat-model.base-url=https://api.deepseek.com
langchain4j.open-ai.chat-model.api-key=${DEEP_SEEK_API_KEY}
langchain4j.open-ai.chat-model.model-name=deepseek-chat

# \u5E94\u7528\u7A0B\u5E8F\u53D1\u9001\u7ED9\u5927\u6A21\u578B\u7684\u8BF7\u6C42\u65E5\u5FD7\u548C\u54CD\u5E94\u65E5\u5FD7
langchain4j.open-ai.chat-model.log-requests=true
langchain4j.open-ai.chat-model.log-responses=true

langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.model-name=deepseek-r1:1.5b
langchain4j.ollama.chat-model.temperature=0.8
langchain4j.ollama.chat-model.timeout=PT60S

# \u5E94\u7528\u7A0B\u5E8F\u53D1\u9001\u7ED9\u5927\u6A21\u578B\u7684\u8BF7\u6C42\u65E5\u5FD7\u548C\u54CD\u5E94\u65E5\u5FD7
langchain4j.ollama.chat-model.log-requests=true
langchain4j.ollama.chat-model.log-responses=true


#\u963F\u91CC\u767E\u70BC\u5E73\u53F0
langchain4j.community.dashscope.chat-model.api-key=${DASH_SCOPE_API_KEY}
langchain4j.community.dashscope.chat-model.model-name=qwen3-max

# \u5C06 \u7CFB\u7EDF\u65E5\u5FD7\u8BBE\u7F6E\u4E3Adebug\u7EA7\u522B
logging.level.root=info

# MongoDB\u8FDE\u63A5\u914D\u7F6E
spring.data.mongodb.uri=mongodb://localhost:27017/chat_memory_db

# \u57FA\u672C\u6570\u636E\u6E90\u914D\u7F6E
spring.datasource.url=jdbc:mysql://localhost:3306/guiguxiaozhi?useUnicode=true@characterEncoding=UTF-8@serverTimezone=Asia/Shanghai@useSSL=false
spring.datasource.username=${MYSQL_USERNAME}
spring.datasource.password=${MYSQL_PASSWORD}
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
# \u5F00\u542F SQL \u65E5\u5FD7\u6253\u5370
mybatis-plus.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl


proxy.enabled=${PROXY_ENABLED}
proxy.host=${PROXY_HOST}
proxy.port=${PROXY_PORT}